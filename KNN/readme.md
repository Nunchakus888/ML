KNN 原理
---------

 1. 假设有一个带有标签的样本数据集（训练样本集），其中包含每条数据与所属分类的对应关系。
 2. 输入没有标签的新数据后，将新数据的每个特征与样本集中数据对应的特征进行比较。

    * 计算新数据与样本数据集中每条数据的距离。
    * 对求得的所有距离进行排序（从小到大，越小表示越相似）。
    * 取前 k （k 一般小于等于 20 ）个样本数据对应的分类标签。

 3. 求 k 个数据中出现次数最多的分类标签作为新数据的分类。




### talk with people's language

给定一个训练数据集，对新的输入实例，在训练数据集中找到与该实例最邻近的 k 个实例，这 k 个实例的多数属于某个类，就把该输入实例分为这个类。

### 开发流程

 1. 收集数据：任何方法
 2. 准备数据：距离计算所需要的数值，最好是结构化的数据格式
 3. 分析数据：任何方法
 4. 训练算法：此步骤不适用于 k-近邻算法
 5. 测试算法：计算错误率
 6. 使用算法：输入样本数据和结构化的输出结果，然后运行
 7. k-近邻算法判断输入数据分类属于哪个分类，最后对计算出的分类执行后续处理

### KNN 算法特点

* 优点：精度高、对异常值不敏感、无数据输入假定
* 缺点：计算复杂度高、空间复杂度高
* 适用数据范围：数值型和标称型
